---
title: "What Can We Be Certain About in the Age of AI?"
date: 2025-04-25
lastmod: 2025-04-25
draft: false
summary: " "

---
The rapid evolution of AI is eroding the sense of control that humans once had over their technological future.

It’s understandable why voices of AI skepticism and even fear are growing louder: **if a form of superintelligence were to surpass all human capabilities, would we merely have served as its evolutionary stepping stone?**

I prefer to return to first principles

and ask:

**What is logically certain about the future of humans in an AI-dominated world?**

### 1.Intelligence ≠ Consciousness

First, we must distinguish **intelligence** from **consciousness.**

**Intelligence** refers to the ability to process information and optimize for goals , an area where AI is already excelling.

**Consciousness** involves subjective experience and self-awareness, a dimension that remains deeply mysterious.

“Intelligence is not consciousness. The ability to process vast amounts of data does not mean an entity experiences feelings.”

Even if future AI systems surpass us in cognition, this does not guarantee they will possess desires, hopes, or emotions.

This aligns with **Integrated Information Theory (IIT)**, which suggests that only systems with highly integrated and irreducible information structures may possess consciousness — a quality not inherent to today’s digital architectures.

Thus:

#### First principle conclusion NO.1 — Intelligence can scale indefinitely without necessarily giving rise to consciousness.

### 2.Types of Behavior and Their Boundaries

Human behavior can be broadly divided into three types:

**(a) Factual Decision-Making**

AI excels at processing massive datasets and optimizing decisions in well-defined domains.

Algorithms can calculate risks and probabilities, but they do not experience fear, hope, or love.

When facing uncertainty, ambiguity, or unprecedented scenarios, human intuition, creativity, and courage remain critical.

**(b) Value Judgments**

AI can simulate ethical reasoning and cultural preferences by learning from existing data.

Studies show that models like ChatGPT can produce moral reasoning responses that even appear “nobler” than human answers , but this is pattern mimicry, not genuine value creation.

As Nick Bostrom emphasizes in Superintelligence, value alignment remains one of the most critical and unresolved challenges in AI safety.

True value judgment involves intentionality and subjective grounding, which current AI lacks.

**(c) Emotional Expression & Experience**

AI can now convincingly simulate emotional expressions — through text, voice, even facial gestures.

However, it does not experience emotions.

The philosopher John Searle’s “Chinese Room” argument remains relevant:

even if a system behaves as though it understands or feels, it may still be entirely devoid of internal experience.

#### First principle conclusion NO.2 — While AI can optimize facts, simulate values, and mimic emotions, it lacks the subjective grounding that underpins human creativity, ethics, and relationships.

### 3.Toward Human-AI Symbiosis: An Inevitable Design Question

Given these boundaries, it becomes clear that:

#### First principle conclusion NO.3 — The future of AI is not about surpassing humans but about designing optimal human-AI symbiosis.

As Kevin Kelly writes in Out of Control, the future belongs to self-organizing systems and collaborative intelligence where humans and machines complement each other’s strengths.

### 4.Why Human-Centered AI Matters More Than Ever

This is why I believe the design philosophy of Human-Centered AI is not merely a preference, it is a logical necessity.

Thus, the crucial questions become:

**How do we design AI that empowers human values, not just optimizes for efficiency?**

**How do we enable AI systems to collaborate, explain, and negotiate with humans, rather than dictate outcomes?**

### 5.A Certain Future

Returning to our initial question:

**What can we be certain about in the age of AI?**

Answer:

AI will continue to dominate factual optimization and become a pervasive infrastructure.

Humans will remain essential for value setting, emotional intelligence, and creative innovation.

The most promising frontier lies in designing new paradigms of human-AI collaboration — not in fearing replacement.

**And that, to me, is the ultimate design space for the future.**

### Final Note

I share these thoughts not as conclusions, but as an ongoing inquiry.
The field of AI is evolving faster than any other in human history. As such, we must continuously revisit our first principles, question assumptions, and deliberately shape the human-AI relationship.

I welcome dialogue with anyone thinking along similar lines.