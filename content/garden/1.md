---
title: "What Can We Be Certain About in the Age of AI?"
date: 2025-04-25
lastmod: 2025-04-25
draft: false
summary: " "

---
The rapid evolution of AI is eroding the sense of control that humans once had over their technological future.

It’s understandable why voices of AI skepticism and even fear are growing louder: **if a form of superintelligence were to surpass all human capabilities, would we merely have served as its evolutionary stepping stone?**

I prefer to return to first principles

and ask:

**What is logically certain about the future of humans in an AI-dominated world?**

### 1.Intelligence ≠ Consciousness

First, we must distinguish **intelligence** from **consciousness.**

**Intelligence** refers to the ability to process information and optimize for goals , an area where AI is already excelling.

**Consciousness** involves subjective experience and self-awareness, a dimension that remains deeply mysterious.

“Intelligence is not consciousness. The ability to process vast amounts of data does not mean an entity experiences feelings.”

Even if future AI systems surpass us in cognition, this does not guarantee they will possess desires, hopes, or emotions.

This aligns with **Integrated Information Theory (IIT)**, which suggests that only systems with highly integrated and irreducible information structures may possess consciousness — a quality not inherent to today’s digital architectures.

Thus:

#### First principle conclusion NO.1 — Intelligence can scale indefinitely without necessarily giving rise to consciousness.

### 2.Without Consciousness → Boundaries on AI’s Role in Value & Emotion

Human behavior can be broadly divided into three types:

**(a) Factual Decision-Making**

AI excels at processing massive datasets and optimizing decisions in well-defined domains.

Algorithms can calculate risks and probabilities, but they do not experience fear, hope, or love.

When facing uncertainty, ambiguity, or unprecedented scenarios, human intuition, creativity, and courage remain critical.

**(b) Value Judgments**

AI can simulate ethical reasoning and cultural preferences by learning from existing data.

Studies show that models like ChatGPT can produce moral reasoning responses that even appear “nobler” than human answers , but this is pattern mimicry, not genuine value creation.

As Nick Bostrom emphasizes in Superintelligence, value alignment remains one of the most critical and unresolved challenges in AI safety.

True value judgment involves intentionality and subjective grounding, which current AI lacks.

**(c) Emotional Expression & Experience**

AI can now convincingly simulate emotional expressions through text, voice, even facial gestures.

However, it does not experience emotions.

The philosopher John Searle’s “Chinese Room” argument remains relevant:

even if a system behaves as though it understands or feels, it may still be entirely devoid of internal experience.

This foundational divide has direct consequences:

**An entity lacking consciousness cannot originate values, nor authentically experience emotions.**

#### First principle conclusion NO.2 — Without consciousness, AI remains bounded to factual optimization and performative simulation; authentic value creation and emotional experience remain inherently human domains.

### 3.Given These Boundaries → Human-AI Collaboration Becomes the Inevitable Paradigm

Given that AI’s role is bounded in this way, what is the logical design direction for future systems?

**The answer is not human replacement, but human-AI symbiosis.**

As Kevin Kelly predicts in Out of Control, future systems will be self-organizing, collaborative ecologies where human and machine intelligences amplify one another.

Similarly, Marshall McLuhan’s insight that “media are extensions of man” applies perfectly to AI — it is becoming a cognitive extension, not a substitute.

Therefore:

#### First principle conclusion NO.3 — The optimal future lies in designing human-centered, collaborative AI — systems that empower human creativity, values, and agency, rather than replacing them.

### 4.Why Human-Centered AI Matters More Than Ever

This is why I believe the design philosophy of Human-Centered AI is not merely a preference, it is a logical necessity.

If AI will excel in processing what is, humans must retain leadership in defining what ought to be: values, meaning, purpose......

Thus, the crucial questions become:

**How can AI systems enhance human value creation and creative expression?**

**How can AI be designed to support transparent, collaborative dialogue with human users?**

**How can we ensure AI remains an extension of human will, rather than an opaque agent of optimization?**

### 5.A Certain Future

Returning to our initial question:

**What can we be certain about in the age of AI?**

Answer:

AI will continue to dominate factual optimization and become a pervasive infrastructure.

Humans will remain essential for value setting, emotional intelligence, and creative innovation.

The most promising frontier lies in designing new paradigms of human-AI collaboration, not in fearing replacement.

**And that, to me, is the ultimate design space for the future.**

### Final Note

I share these thoughts not as conclusions, but as an ongoing inquiry.
The field of AI is evolving faster than any other in human history. As such, we must continuously revisit our first principles, question assumptions, and deliberately shape the human-AI relationship.

I welcome dialogue with anyone thinking along similar lines.